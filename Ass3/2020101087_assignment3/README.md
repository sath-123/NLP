### The Project contains the implementation of two types of word embedding models, Frequency Based and Prediction based.

   -  Frequency Based Embedding: The embeddings were generated by using a corpora specified co-occurrence matrix followed by the implementation of Singular Value Decomposition on the data.
   - Prediction Based Embedding: The word vectors were trained using a word2vec algorithm followed by Negative Sampling to reduce the computation costs and approximate the process.


### 2 files one for svd model in svd.py and other for CBOW with negative sampling in word2vec.py



### svd.py file (frequency based embedding model)
### main functions
- cleaning(),tokenization() for preprocessing the data
- makevocab() for making vocabulary
- co_matrix for finding the co_occurence matrix with window size 4
- SVD() to persom decomposition on above matrix
- Top_10() for finding the top 10 similar words
- next after doing truncated svd on matrix all the trained embeddings are saved in .csv file and dict vocabulary in .txt file 
- next we load the word_vectors and vocabulary and will plot 2D 
- to run the file python3 svd.py

### word2vec.py 
### main functions
- cleaning() and tokenization() for preprocessing the data
- Top_10() will do same work as in svd.py
- we will find context,target,negative samples and train the model and saved the model weights and vocabulary
- file can be run by word2vec.py and trained word_vectors and vocabulary is loaded

### for both svd and word2vec ,vocabulary and trained word vectors are uploaded to google drive
- https://drive.google.com/drive/folders/1resbKxFbjKHe4kBhMzU93E5vw37R0gst?usp=sharing